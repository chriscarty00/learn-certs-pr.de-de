### YamlMime:Course
title: Implementing an Azure Data Solution
metadata:
  title: 'Kurs DP-200T01-A: Implementing an Azure Data Solution'
  description: 'Kurs DP-200T01-A: Implementing an Azure Data Solution'
uid: course.dp-200t01
courseNumber: 'DP-200T01-A'
hoursToComplete: 72
iconUrl: /media/learn/certification/course.svg
learningPartnersLink: https://www.microsoft.com/learning/partners.aspx
locales:
- en
levels:
- intermediate
roles:
- data-engineer
products:
- azure
- azure-cosmos-db
- azure-data-lake
- azure-sql-data-warehouse
- azure-databricks
- azure-notebooks
- azure-stream-analytics
- azure-sql-database
- azure-storage
- azure-monitor
- azure-hdinsight
exams:
- uid: exam.dp-200
summary: |-
  In diesem Kurs implementieren die Teilnehmer verschiedene Datenplattformtechnologien in Lösungen , die den geschäftlichen und technischen Anforderungen entsprechen, einschließlich On-Premises-, Cloud- und hybride Datenszenarien, die sowohl relationale als auch NoSQL-Daten beinhalten. Sie lernen außerdem, wie Daten mit einer Reihe von Technolofien und Sprachen für Streaming und Batch daten verarbeitet werden.

  Die Teilnehmer erkunden die Implementation von Datensicherheit, dazu gehört die Autentifizierung, Autorisation, Datenrichtlinien und Standards. Außerdem definieren und implementieren sie Datenlösungen die Datenspeicher und Datenverarbeitung überwachen. Zum Schluss erledigen Sie die Verwaltung und Fehlerbehebung von Azure-Datenlösungen inklusive der Optimierung und Disaster Recovery von großen Daten, Batchverarbeitung und Streaming Datenlösungen.

  #### Zielgruppenprofil
  Die primäre Zielgruppe für diesen Kurs sind Datenexperten, Datenarchitekten und Business Intelligence-Experten, die sich über die Datenplattformtechnologien, die auf Microsoft Azure existieren, informieren möchten. Die sekundäre Zielgruppe für diesen Kurs sind Personen, die Anwendungen entwickeln, die Inhalte aus den Datenplattformtechnologien, die auf Microsoft Azure existieren, bereitstellen.
prerequisitesSection: |-
  Zusätzlich zu ihrer Beruflichen Erfahrun sollten die Teilnehmer des Kurses technische Kenntnisse, die mit folgenden Kursen übereinstimmen, besitzen&#58;
  - [Azure Fundamentals](https://docs.microsoft.com/learn/modules/welcome-to-azure/)
outlineSection: |-
  ### Modul 1&#58; Azure für den Data Engineer
  In diesem Modul wird  die Entwicklungen in der Welt der Daten untersucht und wie die Technologien der Cloud-Datenplattformen den Unternehmen neue Möglichkeiten bieten, ihre Daten auf unterschiedliche Weise zu erkunden Die Teilnehmer erhalten einen Überblick über die verschiedenen verfügbaren Datenplattformtechnologien und wie sich die Rolle und die Verantwortlichkeiten eines Datentechnikers entwickelt haben, um in dieser neuen Welt zum Nutzen einer Organisation zu arbeiten.
  #### Lektionen
  - fortschreitende Datenwelt erklären
  - Services in der Azure Datenplattform untersuchen
  - Aufgaben die von Datentechniker ausgeführt werden identifizieren
  - Die Nutzungsfälle für die Cloud in einer Fallstudie beschreiben


  #### Labor&#58; Azure für den Data Engineer
  - Die entwickung der Welt der Daten identifizieren
  - Azure Data Platform Services festlegen
  - Aufgaben des Datentechnikers identifizieren
  - Die Datentechniker Lieferungen beenden

  Nach Abschluss dieses Moduls können die Teilnehmer&#58;
  - fortschreitende Datenwelt erklären
  - Services in der Azure Datenplattform untersuchen
  - Aufgaben die von Datentechniker ausgeführt werden identifizieren
  - Die Nutzungsfälle für die Cloud in einer Fallstudie beschreiben


  ### Modul 2&#58; Mit Datenspeicher arbeiten
  Dieses Modul lehrt eine Vielzahl an Datenspeichermöglichkeiten in Azure. Die Teilnehmer lernen die Grundlagen der Speicherverwaltung in Azure, das Anlegen eines Storage-Accounts und die Auswahl des richtigen Modells für die Daten, die in der Cloud gespeichert werden sollen. Sie werden auch verstehen, wie Data Lake-Speicher erstellt werden können, um eine Vielzahl von großen Datenanalyselösungen mit minimalem Aufwand zu unterstützen.
  #### Lektionen
  - Datenspeicheransatz in Azure auswählen
  - Erstellen und Konfigurieren von Speicherkonten
  - Azure Data Lake Analytics erklären
  - Daten in Azure Data Lake speichern


  #### Labor&#58; Working with Data Storage
  - Datenspeicheransatz in Azure auswählen
  - Speicherkonten erstellen
  - Data Lake Storage erklären
  - Daten in Data Lake Stores hochladen

  Nach Abschluss dieses Moduls können die Teilnehmer&#58;
  - Datenspeicheransatz in Azure auswählen
  - Erstellen und Konfigurieren von Speicherkonten
  - Azure Data Lake Analytics erklären
  - Daten in Azure Data Lake speichern


  ### Modul 3&#58; Enabling Team Based Data Science with Azure Databricks
  Dieses Modul stellt die Azure-databricks vor und erklärt wie ein Datentechniker mit ihnen arbeitet, um es der Organisaiton zu ermöglichen, Team Data Science Projekte durchzuführen. Die Teilnehmer lernen die Grundlagen von Azure-databricks kennen und von apache Spark Notebooks; wie der Dienst und der Arbeitsplatz bereitgestellt wir; und wie Datenvorbereitungsaufgaben die zum Data Science Projekt gehören ausgeführt werden.
  #### Lektionen
  - Azure-Databricks erklären
  - mit Azure-databricks arbeiten
  - Einlesen von Daten in Azure Databricks
  - Transformationen mit Azure-databricks durchführen


  #### Labor&#58; Enabling Team Based Data Science with Azure Databricks
  - Azure-Databricks erklären
  - mit Azure-databricks arbeiten
  - Einlesen von Daten in Azure Databricks
  - Transformationen mit Azure-databricks durchführen

  Nach Abschluss dieses Moduls können die Teilnehmer&#58;
  - Azure-Databricks erklären
  - mit Azure-databricks arbeiten
  - Einlesen von Daten in Azure Databricks
  - Transformationen mit Azure-databricks durchführen


  ### Modul 4&#58; Building Globally Distributed Databases with Cosmos DB
  In diesem Modul lernen die Teilnehmer, mit  NoSQl Daten mithilfe von Azure Cosmos DB zu arbeiten Sie lernen, wie der Service bereitgestellt wird, wie sie Daten in den Service via Visual Studio Code Erweiterungen laden lännen und den Azure Cosmos DB NET Core SDK. Außerdem lernen sie wie Verfügbarkeitsoptionen konfiguriert werden, so dass Nutzer weltweit auf die Daten zugreifen könen.
  #### Lektionen
  - Azure Cosmos DB Datenbank built to scale erstellen
  - Daten in die Azure Cosmos DB Datenbank einfügen
  - NET Coreapp für Cosmos DB in Visual Studio Code bauen
  - Daten weltweit mit Azure Cosmos DB verteilen


  #### Labor&#58; Building Globally Distributed Databases with Cosmos DB
  - Azure Cosmos DB erstellen
  - Daten in Azure Cosmos DB einfügen
  - NET Core App für Azure Cosmos DB mit VS Code erstellen
  - Daten weltweit mit Azure Cosmos DB verteilen

  Nach Abschluss dieses Moduls können die Teilnehmer&#58;
  - Azure Cosmos DB Datenbank built to scale erstellen
  - Daten in die Azure Cosmos DB Datenbank einfügen
  - NET Core App für Azure Cosmos DB mit VS Code erstellen
  - Daten weltweit mit Azure Cosmos DB verteilen


  ### Modul 5&#58; Working with Relational Data Stores in the Cloud
  In diesem Modul werden die Teilnehmer die Optionen der relationalen Datenplattform Azure, einschließlich der SQL-Datenbank und des SQL Data Warehouse, erforschen. Die Teilnehmer können danach erklären, warum sie eine Dienstleistung einer anderen vorziehen würden und wie sie jede der Dienstleistungen bereitstellen, verbinden und verwalten können.
  #### Lektionen
  - Azure SQL-Datenbank verwenden
  - Implementierung einer SQL-Datenbank
  - Ein Azure SQL Data Warehouse entwerfen und implementieren
  - PolyBase Nutzen um Daten nach Azure SQL Data Warehouse zu laden


  #### Labor&#58; Working with Relational Data Stores in the Cloud
  - Azure SQL-Datenbank verwenden
  - Implementierung einer SQL-Datenbank
  - Ein Azure SQL Data Warehouse entwerfen und implementieren
  - PolyBase Nutzen um Daten nach Azure SQL Data Warehouse zu laden

  Nach Abschluss dieses Moduls können die Teilnehmer&#58;
  - Azure SQL-Datenbank verwenden
  - Azure Data Warehouse Beschreiben
  - Ein Azure SQL Data Warehouse entwerfen 
  - PolyBase Nutzen um Daten nach Azure SQL Data Warehouse zu laden


  ### Modul 6&#58; Performing Real-Time Analytics with Stream Analytics
  In diesem Modul lernen die Teilnehmer die Konzepte der Ereignisverarbeitung und Datenstreaming kennen und wie dies auf Event Hubs und Azure-stream-analytics zutrifft. Die Teilnehmer richten dann einen Stream Analytics Job ein, um Daten zu streamen und lernen, wie man die eingehenden Daten abfragt, um die Analyse der Daten durchzuführen. Zum Schluss lernen sie, wie laufende Jobs verwaltet und überwacht werden
  #### Lektionen
  - Datenströme un Ereignisverarbeitung erklären
  - Datenaufnahme mit Event Hubs
  - Datenverarbeitung mit Stream Analytics Jobs


  #### Labor&#58; Performing Real-Time Analytics with Stream Analytics
  - Datenströme un Ereignisverarbeitung erklären
  - Datenaufnahme mit Event Hubs
  - Datenverarbeitung mit Stream Analytics Jobs

  Nach Abschluss dieses Moduls, können die Teilnehmer&#58;
  - Datenströme und Ereignisverarbeitung erklären
  - Datenaufnahme mit Event Hubs verstehen
  - Datenverarbeitung mit Stream Analytics Jobs verstehen


  ### Modul 7&#58; Orchestrating Data Movement with Azure Data Factory
  In diesem Modul lernen die Teilnehmer, wie Azure Data Factory verwendet werden kann um Datenbewegungen und Transformationen aus einer reihe von Data Platform Technologien gelenkt werden können. Sie werden die Möglichkeiten der Technologie erklären können und eine End-to-End Datenpipeline aufbauen können, die Daten aufnimmt und transformiert.
  #### Lektionen
  - erklären, wie Data Factory funktioniert
  - Azure Data Factory Komponenten
  - Azure Data Factory und Databricks


  #### Labor&#58; Orchestrating Data Movement with Azure Data Factory
  - erklären, wie Data Factory funktioniert
  - Azure Data Factory Komponenten
  - Azure Data Factory und Databricks

  Nach Abschluss dieses Moduls, können die Teilnehmer&#58;
  - Azure Data Factory und Databricks verstehen
  - Azure Data Factory Komponenten verstehen
  - erklären, wie Azure Data Factory funktioniert


  ### Modul 8&#58; Securing Azure Data Platforms
  In diesem Modul lernen die Teilnehmer, wie Azure mehrschichtige Sicherheitsmodelle für den Datenschutz einsetzt. Die Teilnehme untersuchen, wie Sicherheit von der Einrichtung sicherer Netzwerke und Zugangsschlüssel über die Definition von Berechtigungen bis hin zur Überwachung über eine Reihe von Datenspeichern reichen kann.
  #### Lektionen
  - Einführung in die Sicherheit
  - Sicherheits-Schlüsselkomponenten
  - Speicherkonten und Data Lake Storage sichern
  - Datenspeicher sichern
  - Streamingdaten sichern


  #### Labor&#58; Securing Azure Data Platforms
  - Einführung in die Sicherheit
  - Sicherheits-Schlüsselkomponenten
  - Speicherkonten und Data Lake Storage sichern
  - Datenspeicher sichern
  - Streamingdaten sichern

  Nach Abschluss dieses Moduls, können die Teilnehmer&#58;
  - Grundlagen der Sicherheit beherrschen
  - Schlüsselkomponenten der Sicherung verstehen
  - Speicherkonten und Data Lake Speicher verstehen
  - Datenspeichersicherung verstehen
  - Streamingdatensicherung verstehen


  ### Modul 9&#58; Monitoring and Troubleshooting Data Storage and Processing
  In diesem Modul erhalten die Teilnehmer einen Überblick über die Bandbreite der Überwachungsmöglichkeiten, die zur Unterstützung des Betriebs zur Verfügung stehen, falls es Probleme mit einer Datenplattformarchitektur gibt. Sie untersuchen übliche Datenspeicher und Datenverarbeitungsprobleme. Disaster Recoveryoptionen werden zum Schluss gezeigt um die Geschäftskontinuität zu gewährleisten.
  #### Lektionen
  - verfügbare Überwachungsmöglichkeiten erklären
  - Geöhnliche Datenspeicherprobleme beheben
  - gewöhnliche Datenverarbeitungsprobleme beheben
  - Verwalten Notfallwiederherstellung


  #### Labor&#58; Monitoring and Troubleshooting Data Storage and Processing
  - verfügbare Überwachungsmöglichkeiten erklären
  - Geöhnliche Datenspeicherprobleme beheben
  - gewöhnliche Datenverarbeitungsprobleme beheben
  - Verwalten Notfallwiederherstellung

  Nach Abschluss dieses Moduls können die Teilnehmer&#58;
  - verfügbare Überwachungsmöglichkeiten erklären
  - Geöhnliche Datenspeicherprobleme beheben
  - gewöhnliche Datenverarbeitungsprobleme beheben
  - Verwalten Notfallwiederherstellung